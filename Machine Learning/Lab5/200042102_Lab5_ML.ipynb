{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Msv-pr01nGA8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "%matplotlib inline\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader,random_split\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "metadata": {
        "id": "0UUv6dZt5KmZ"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 8.1\n",
        "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())"
      ],
      "metadata": {
        "id": "91dvp1iHnMKF"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 8.2\n",
        "selected_classes = [0,1,2,3,4]\n",
        "\n",
        "indices = [i for i, label in enumerate(dataset.targets) if label in selected_classes]\n",
        "\n",
        "subset_dataset = torch.utils.data.Subset(dataset, indices)\n",
        "\n",
        "train_size = int(0.7 * len(subset_dataset))\n",
        "val_size = int(0.15 * len(subset_dataset))\n",
        "test_size = len(subset_dataset) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(subset_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "eHtu5dZanp0V"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 8.3\n",
        "class SimpleNeuralNet(torch.nn.Module):\n",
        "  def __init__(self, input_size, num_neurons):\n",
        "    super(SimpleNeuralNet, self).__init__()\n",
        "    self.flatten = torch.nn.Flatten()\n",
        "    self.fc1 = torch.nn.Linear(input_size, num_neurons)\n",
        "    self.fc2 = torch.nn.Linear(num_neurons, num_neurons)\n",
        "    self.fc3 = torch.nn.Linear(num_neurons, num_neurons)\n",
        "    self.fc4 = torch.nn.Linear(num_neurons, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "tXbRI38InrfV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_neurons = 102\n",
        "input_size = 1 * 28 * 28\n",
        "model = SimpleNeuralNet(input_size, num_neurons)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])"
      ],
      "metadata": {
        "id": "T8rENIzvo8nd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for inputs, labels in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_dataloader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "print('Training complete.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5K3boSNrOtF",
        "outputId": "bd81d06f-5c5e-4dd7-cf44-690eca1fbe0d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Test Accuracy: 0.9630\n",
            "Epoch 2/10, Test Accuracy: 0.9756\n",
            "Epoch 3/10, Test Accuracy: 0.9769\n",
            "Epoch 4/10, Test Accuracy: 0.9821\n",
            "Epoch 5/10, Test Accuracy: 0.9858\n",
            "Epoch 6/10, Test Accuracy: 0.9834\n",
            "Epoch 7/10, Test Accuracy: 0.9867\n",
            "Epoch 8/10, Test Accuracy: 0.9769\n",
            "Epoch 9/10, Test Accuracy: 0.9874\n",
            "Epoch 10/10, Test Accuracy: 0.9876\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 8.4\n",
        "torch.manual_seed(42)\n",
        "\n",
        "class ConvulationalNeuralNet(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "        super(ConvulationalNeuralNet, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.flatten = torch.nn.Flatten()\n",
        "        self.fc1 = torch.nn.Linear(64 * 7 * 7 * 16, 128)\n",
        "        self.fc2 = torch.nn.Linear(128, 64)\n",
        "        self.fc3 = torch.nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = torch.relu(self.conv3(x))\n",
        "        #print(x.size())\n",
        "        x = self.flatten(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "tj2CTHsTrfjW"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = (1, 28, 28)\n",
        "model = ConvulationalNeuralNet()\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "ztaOLI1HtZ7e"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for inputs, labels in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_dataloader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "print('Training complete.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHHAC46OtnqP",
        "outputId": "b59ab4ca-7f54-4081-fbc3-d2e1bcdcc6b3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Test Accuracy: 0.9815\n",
            "Epoch 2/10, Test Accuracy: 0.9845\n",
            "Epoch 3/10, Test Accuracy: 0.9908\n",
            "Epoch 4/10, Test Accuracy: 0.9904\n",
            "Epoch 5/10, Test Accuracy: 0.9926\n",
            "Epoch 6/10, Test Accuracy: 0.9937\n",
            "Epoch 7/10, Test Accuracy: 0.9939\n",
            "Epoch 8/10, Test Accuracy: 0.9930\n",
            "Epoch 9/10, Test Accuracy: 0.9926\n",
            "Epoch 10/10, Test Accuracy: 0.9911\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 8.5\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "class ConvulationalNeuralNet(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "        super(ConvulationalNeuralNet, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv3 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool3 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.flatten = torch.nn.Flatten()\n",
        "        self.fc1 = torch.nn.Linear(64 * 3 * 3, 128)\n",
        "        self.fc2 = torch.nn.Linear(128, 64)\n",
        "        self.fc3 = torch.nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "        x = self.pool1(torch.relu(self.conv1(x)))\n",
        "        x = self.pool2(torch.relu(self.conv2(x)))\n",
        "        x = self.pool3(torch.relu(self.conv3(x)))\n",
        "        #print(x.size())\n",
        "        x = self.flatten(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "input_size = (1, 28, 28)\n",
        "model = ConvulationalNeuralNet()\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for inputs, labels in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_dataloader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "print('Training complete.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahdhI9MVtqTG",
        "outputId": "c1e3027f-9206-4ec7-b019-3e1be2742fc8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Test Accuracy: 0.9717\n",
            "Epoch 2/10, Test Accuracy: 0.9850\n",
            "Epoch 3/10, Test Accuracy: 0.9863\n",
            "Epoch 4/10, Test Accuracy: 0.9919\n",
            "Epoch 5/10, Test Accuracy: 0.9935\n",
            "Epoch 6/10, Test Accuracy: 0.9889\n",
            "Epoch 7/10, Test Accuracy: 0.9937\n",
            "Epoch 8/10, Test Accuracy: 0.9954\n",
            "Epoch 9/10, Test Accuracy: 0.9956\n",
            "Epoch 10/10, Test Accuracy: 0.9959\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 8.6\n",
        "torch.manual_seed(42)\n",
        "\n",
        "class ConvulationalNeuralNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvulationalNeuralNet, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout1 = torch.nn.Dropout(0.25)\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout2 = torch.nn.Dropout(0.25)\n",
        "        self.conv3 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool3 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout3 = torch.nn.Dropout(0.25)\n",
        "        self.flatten = torch.nn.Flatten()\n",
        "        self.fc1 = torch.nn.Linear(64 * 3 * 3, 128)\n",
        "        self.fc2 = torch.nn.Linear(128, 64)\n",
        "        self.fc3 = torch.nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(torch.relu(self.conv1(x)))\n",
        "        x = self.dropout1(x)\n",
        "        x = self.pool2(torch.relu(self.conv2(x)))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.pool3(torch.relu(self.conv3(x)))\n",
        "        x = self.dropout3(x)\n",
        "        x = self.flatten(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "input_size = (1, 28, 28)\n",
        "model = ConvulationalNeuralNet()\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for inputs, labels in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_dataloader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "print('Training complete.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-pyvjLqx_HG",
        "outputId": "86b3718d-d890-40f7-bcab-d2250459eafe"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Test Accuracy: 0.9767\n",
            "Epoch 2/10, Test Accuracy: 0.9850\n",
            "Epoch 3/10, Test Accuracy: 0.9898\n",
            "Epoch 4/10, Test Accuracy: 0.9900\n",
            "Epoch 5/10, Test Accuracy: 0.9915\n",
            "Epoch 6/10, Test Accuracy: 0.9930\n",
            "Epoch 7/10, Test Accuracy: 0.9935\n",
            "Epoch 8/10, Test Accuracy: 0.9939\n",
            "Epoch 9/10, Test Accuracy: 0.9930\n",
            "Epoch 10/10, Test Accuracy: 0.9952\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 8.7\n",
        "\n",
        "model = ConvulationalNeuralNet()\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "augmentation_transform = transforms.Compose([\n",
        "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
        "    transforms.RandomRotation(degrees=30),\n",
        "])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)),\n",
        "    augmentation_transform\n",
        "])\n",
        "writer = SummaryWriter()\n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for batch_idx, (inputs, labels) in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        writer.add_scalar('Loss/Train', loss.item(), epoch * len(train_dataloader) + batch_idx)\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_dataloader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    writer.add_scalar('Accuracy/Validation', accuracy, epoch)\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "print('Training complete.')\n",
        "writer.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Epj2HMXM0SaS",
        "outputId": "dc800338-65e7-4485-8a41-8ca8c5922b76"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Test Accuracy: 0.9850\n",
            "Epoch 2/20, Test Accuracy: 0.9887\n",
            "Epoch 3/20, Test Accuracy: 0.9917\n",
            "Epoch 4/20, Test Accuracy: 0.9919\n",
            "Epoch 5/20, Test Accuracy: 0.9935\n",
            "Epoch 6/20, Test Accuracy: 0.9948\n",
            "Epoch 7/20, Test Accuracy: 0.9943\n",
            "Epoch 8/20, Test Accuracy: 0.9952\n",
            "Epoch 9/20, Test Accuracy: 0.9956\n",
            "Epoch 10/20, Test Accuracy: 0.9943\n",
            "Epoch 11/20, Test Accuracy: 0.9950\n",
            "Epoch 12/20, Test Accuracy: 0.9952\n",
            "Epoch 13/20, Test Accuracy: 0.9956\n",
            "Epoch 14/20, Test Accuracy: 0.9952\n",
            "Epoch 15/20, Test Accuracy: 0.9967\n",
            "Epoch 16/20, Test Accuracy: 0.9963\n",
            "Epoch 17/20, Test Accuracy: 0.9976\n",
            "Epoch 18/20, Test Accuracy: 0.9974\n",
            "Epoch 19/20, Test Accuracy: 0.9967\n",
            "Epoch 20/20, Test Accuracy: 0.9959\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "8qhHCE6b5DSd"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nLupzrg47Ya6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}